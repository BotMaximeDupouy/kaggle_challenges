{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "73cfd06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c6bff1",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "56e55862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c626fb1e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data explo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a4949",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Shape, size, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7c489b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b83f634",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eee54d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c3a094",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.57034\n",
       "1    0.42966\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda1b88",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Nan number ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191c5daf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506daf3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets drop location and id columns and explore keyword column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cebab5c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## keyword column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b487a8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0868dfa9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['location' 'id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/337182291.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4899\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4900\u001b[0m         \"\"\"\n\u001b[0;32m-> 4901\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4902\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4903\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4147\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4180\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['location' 'id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_copy.drop(columns=['location', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16efa054",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_copy.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c261b0f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5080, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "332a0a9e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['keyword'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d2a47",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the moment i will not use the keyword column, because of the nan number, but i think it is an interesting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484543f",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ef251",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approche de base : on se concentre sur les commentaires uniquement\n",
    "df.drop(columns=['location', 'id', 'keyword'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "9ddff736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text, remove_punctuations=False, lower_case=False,remove_numb=False, remove_symbol=False):\n",
    "    for index, sentence in enumerate(text) : \n",
    "        if remove_punctuations == True :\n",
    "            for punctuation in string.punctuation:\n",
    "                sentence = sentence.replace(punctuation, '')\n",
    "        if lower_case == True :\n",
    "            sentence = sentence.lower()\n",
    "        if remove_numb == True :\n",
    "            sentence = ''.join(word for word in sentence if not word.isdigit())\n",
    "        if remove_symbol == True :\n",
    "            sentence = ''.join(char if char not in ['#', '@', \"&\", \"\\(\", \"\\)\", \"_\", \"$\", \"£\", \"%\", \"/\", \"\\\\\"] else ' ' for char in sentence)\n",
    "        text[index] = sentence\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a6b53cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/2174276971.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text[index] = sentence\n"
     ]
    }
   ],
   "source": [
    "df['text'] = clean_data(df['text'], remove_punctuations=True, lower_case=True,remove_numb=True, remove_symbol=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "44019e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/1419358768.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][index] = word_tokenize(df['text'][index])\n",
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/1419358768.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][index] = [t for t in df['text'][index] if t not in stop_words]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  [deeds, reason, earthquake, may, allah, forgiv...       1\n",
       "1      [forest, fire, near, la, ronge, sask, canada]       1\n",
       "2  [residents, asked, shelter, place, notified, o...       1\n",
       "3  [people, receive, wildfires, evacuation, order...       1\n",
       "4  [got, sent, photo, ruby, alaska, smoke, wildfi...       1"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "for index, com in enumerate(df['text']) :\n",
    "    df['text'][index] = word_tokenize(df['text'][index])\n",
    "    df['text'][index] = [t for t in df['text'][index] if t not in stop_words]\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "61f614cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/1521806483.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][index] = [lemmatizer.lemmatize(word) for word in df['text'][index]]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for index, com in enumerate(df['text']) :\n",
    "    df['text'][index] = [lemmatizer.lemmatize(word) for word in df['text'][index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b9d8ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [deed, reason, earthquake, may, allah, forgive...\n",
       "1           [forest, fire, near, la, ronge, sask, canada]\n",
       "2       [resident, asked, shelter, place, notified, of...\n",
       "3       [people, receive, wildfire, evacuation, order,...\n",
       "4       [got, sent, photo, ruby, alaska, smoke, wildfi...\n",
       "                              ...                        \n",
       "7608    [two, giant, crane, holding, bridge, collapse,...\n",
       "7609    [ariaahrary, thetawniest, control, wild, fire,...\n",
       "7610           [utckm, volcano, hawaii, httptcozdtoydebj]\n",
       "7611    [police, investigating, ebike, collided, car, ...\n",
       "7612    [latest, home, razed, northern, california, wi...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b12413",
   "metadata": {},
   "source": [
    "## Vocab Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "7eaf0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_words = []\n",
    "for sentence in df['text'] :\n",
    "    for word in sentence :\n",
    "        list_all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "52abe4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20395"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(set(list_all_words))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "10df4cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/3410932662.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][index] = ' '.join(df['text'][index])\n"
     ]
    }
   ],
   "source": [
    "# je passe les listes de mots en string\n",
    "for index, com in enumerate(df['text']) :\n",
    "    df['text'][index] = ' '.join(df['text'][index])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "1a9f42da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              deed reason earthquake may allah forgive u\n",
       "1                   forest fire near la ronge sask canada\n",
       "2       resident asked shelter place notified officer ...\n",
       "3       people receive wildfire evacuation order calif...\n",
       "4       got sent photo ruby alaska smoke wildfire pour...\n",
       "                              ...                        \n",
       "7608    two giant crane holding bridge collapse nearby...\n",
       "7609    ariaahrary thetawniest control wild fire calif...\n",
       "7610                utckm volcano hawaii httptcozdtoydebj\n",
       "7611    police investigating ebike collided car little...\n",
       "7612    latest home razed northern california wildfire...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "94c8c91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>two giant crane holding bridge collapse nearby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>ariaahrary thetawniest control wild fire calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>utckm volcano hawaii httptcozdtoydebj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>police investigating ebike collided car little...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>latest home razed northern california wildfire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0            deed reason earthquake may allah forgive u       1\n",
       "1                 forest fire near la ronge sask canada       1\n",
       "2     resident asked shelter place notified officer ...       1\n",
       "3     people receive wildfire evacuation order calif...       1\n",
       "4     got sent photo ruby alaska smoke wildfire pour...       1\n",
       "...                                                 ...     ...\n",
       "7608  two giant crane holding bridge collapse nearby...       1\n",
       "7609  ariaahrary thetawniest control wild fire calif...       1\n",
       "7610              utckm volcano hawaii httptcozdtoydebj       1\n",
       "7611  police investigating ebike collided car little...       1\n",
       "7612  latest home razed northern california wildfire...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je fais une copie pour une autre approche\n",
    "df_copy_word2vec = df.copy()\n",
    "df_copy_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "98502518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# je transform les mots en int\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(df['text'])\n",
    "df['text'] = tk.texts_to_sequences(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "d5490202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [4018, 452, 156, 69, 1399, 4019, 6]\n",
       "1                    [107, 1, 149, 504, 5984, 5985, 1067]\n",
       "2       [1530, 1400, 1879, 453, 5986, 319, 162, 1879, ...\n",
       "3                            [10, 4020, 76, 162, 361, 32]\n",
       "4          [31, 1068, 111, 5987, 1692, 187, 76, 5988, 97]\n",
       "                              ...                        \n",
       "7608        [55, 692, 1047, 940, 255, 83, 563, 22, 20394]\n",
       "7609    [5959, 5960, 715, 214, 1, 32, 92, 116, 294, 12...\n",
       "7610                              [3755, 446, 1388, 5954]\n",
       "7611    [21, 991, 2838, 259, 43, 195, 4704, 2838, 1701...\n",
       "7612          [131, 22, 451, 116, 32, 76, 522, 11, 20395]\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['text']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "a9629d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.018e+03, 4.520e+02, 1.560e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.070e+02, 1.000e+00, 1.490e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.530e+03, 1.400e+03, 1.879e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [3.755e+03, 4.460e+02, 1.388e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.100e+01, 9.910e+02, 2.838e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.310e+02, 2.200e+01, 4.510e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je pad\n",
    "X_pad = pad_sequences(X, dtype='float32', padding='post')\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "fb7babfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul sequence max\n",
    "Max_sentence_length = max([len(com) for com in X_pad])\n",
    "Max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "082066f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spit data\n",
    "X_pad_train = X_pad[:5000]\n",
    "X_pad_test = X_pad[5000:]\n",
    "y_train = df['target'][:5000]\n",
    "y_test = df['target'][5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ec2f6",
   "metadata": {},
   "source": [
    "# Model personnal embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "13221aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 23, 100)           2039600   \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 500)               1202000   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 3,242,101\n",
      "Trainable params: 3,242,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Embedding(input_dim=vocab_size, output_dim=emb_dim, mask_zero=True)\n",
    "from tensorflow.keras import layers, Sequential\n",
    "# Size of your embedding space = size to represent each word\n",
    "embedding_size = 100\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size+1,\n",
    "input_length=Max_sentence_length, \n",
    "output_dim=embedding_size,\n",
    "mask_zero=True))\n",
    "model.add(layers.LSTM(500))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "3eec4d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximedupouy/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:5016: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 14s 54ms/step - loss: 0.3475 - accuracy: 0.8657 - recall: 0.7747 - val_loss: 0.5993 - val_accuracy: 0.7040 - val_recall: 0.6652\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 11s 52ms/step - loss: 0.2476 - accuracy: 0.9126 - recall: 0.8510 - val_loss: 0.6158 - val_accuracy: 0.7013 - val_recall: 0.6608\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 11s 48ms/step - loss: 0.1669 - accuracy: 0.9431 - recall: 0.9082 - val_loss: 0.6761 - val_accuracy: 0.6860 - val_recall: 0.6416\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 11s 49ms/step - loss: 0.1162 - accuracy: 0.9620 - recall: 0.9357 - val_loss: 1.0804 - val_accuracy: 0.6227 - val_recall: 0.7581\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 11s 48ms/step - loss: 0.0845 - accuracy: 0.9737 - recall: 0.9605 - val_loss: 0.8568 - val_accuracy: 0.6433 - val_recall: 0.6962\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 11s 48ms/step - loss: 0.0615 - accuracy: 0.9843 - recall: 0.9753 - val_loss: 0.9888 - val_accuracy: 0.6327 - val_recall: 0.6224\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.0530 - accuracy: 0.9863 - recall: 0.9795 - val_loss: 1.0094 - val_accuracy: 0.6240 - val_recall: 0.6799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8fb81f0>"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "es = EarlyStopping(patience=6, restore_best_weights=True)\n",
    "loss=BinaryCrossentropy(from_logits=True) # default from_logits=False\n",
    "#metrics=[keras.metrics.BinaryAccuracy()]\n",
    "model.compile(loss=loss,\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy', 'Recall'])\n",
    "model.fit(X_pad_train, y_train, epochs=20, batch_size=16, verbose=1, callbacks=[es], validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "bb786b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 2s 22ms/step - loss: 0.5177 - accuracy: 0.7386 - recall: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5177033543586731, 0.7386146187782288, 0.7383177280426025]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_pad_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea9fb5",
   "metadata": {},
   "source": [
    "# challenge kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "ff8ca390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_test = 'data/test.csv'\n",
    "test_keras = pd.read_csv(path_test)\n",
    "test_keras.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "f3b3199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  "
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_keras.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21dbaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "c3f73d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_keras.drop(columns=['location', 'keyword'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "22604836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/2174276971.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text[index] = sentence\n"
     ]
    }
   ],
   "source": [
    "test_keras['text'] = clean_data(test_keras['text'], remove_punctuations=True, lower_case=True,remove_numb=True, remove_symbol=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "1a79b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/2197476742.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_keras['text'][index] = word_tokenize(test_keras['text'][index])\n",
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/2197476742.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_keras['text'][index] = [t for t in test_keras['text'][index] if t not in stop_words]\n"
     ]
    }
   ],
   "source": [
    "for index, com in enumerate(test_keras['text']) :\n",
    "    test_keras['text'][index] = word_tokenize(test_keras['text'][index])\n",
    "    test_keras['text'][index] = [t for t in test_keras['text'][index] if t not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "7149655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/2754747523.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_keras['text'][index] = [lemmatizer.lemmatize(word) for word in test_keras['text'][index]]\n"
     ]
    }
   ],
   "source": [
    "for index, com in enumerate(test_keras['text']) :\n",
    "    test_keras['text'][index] = [lemmatizer.lemmatize(word) for word in test_keras['text'][index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "b6ea0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/2163400442.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_keras['text'][index] = ' '.join(test_keras['text'][index])\n"
     ]
    }
   ],
   "source": [
    "for index, com in enumerate(test_keras['text']) :\n",
    "    test_keras['text'][index] = ' '.join(test_keras['text'][index])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "8a6c6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk.fit_on_texts(df['text'])\n",
    "test_keras['text'] = tk.texts_to_sequences(test_keras['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "bd675f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_test = test_keras['text']\n",
    "X_kaggle_test_pad = pad_sequences(X_kaggle_test, dtype='float32', padding='post', maxlen=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e7003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "fd2b947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = model.predict(X_kaggle_test_pad)\n",
    "len(res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "2cad4f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_binary = []\n",
    "for num in res_test : \n",
    "    if num< 0.5:\n",
    "        res_binary.append(0)\n",
    "    else :\n",
    "        res_binary.append(1)\n",
    "len(res_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "0d65bb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = pd.DataFrame(res_binary, columns=['target'])\n",
    "res_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "f19823c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test['id']= test_keras['id']\n",
    "res_test = res_test[['id', 'target']]\n",
    "res_test\n",
    "#res_test[res_test['id']== 2275]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "86ba2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test.to_csv('challenge_kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d68b16",
   "metadata": {},
   "source": [
    "# approche avec un autre modele "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520ea49",
   "metadata": {},
   "source": [
    "\n",
    "for index, word in enumerate (df_copy_word2vec['text']) :\n",
    "    df_copy_word2vec['text'][index] = df_copy_word2vec['text'][index].split()\n",
    "X_word2vec = df_copy_word2vec['text']  \n",
    "X_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "728235f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from gensim.models import Word2Vec\\n\\n# This line trains an entire embedding for the words in your train set\\nword2vec = Word2Vec(sentences=X_word2vec, vector_size=100)\\nword2vec'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from gensim.models import Word2Vec\n",
    "\n",
    "# This line trains an entire embedding for the words in your train set\n",
    "word2vec = Word2Vec(sentences=X_word2vec, vector_size=100)\n",
    "word2vec'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "319552e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = df_copy_word2vec['text'][:5000]\n",
    "X_test_2 = df_copy_word2vec['text'][5000:]\n",
    "y_train_2 = df_copy_word2vec['target'][:5000]\n",
    "y_test_2 = df_copy_word2vec['target'][5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1b88253c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_transfer = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "len(word2vec_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "e33db687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/v4zjj0453jl2v5pmlsvnhgnc0000gn/T/ipykernel_41468/4255283349.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(embed)\n"
     ]
    }
   ],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return np.array(embed)\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed_2 = embedding(word2vec_transfer, X_train_2)\n",
    "X_test_embed_2 = embedding(word2vec_transfer, X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "bb94680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad_2 = pad_sequences(X_train_embed_2, dtype='float32', padding='post', value=0.)\n",
    "X_test_pad_2 = pad_sequences(X_test_embed_2, dtype='float32', padding='post', value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a4947e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 117, 50)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "630e51c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 11s 39ms/step - loss: 0.6731 - accuracy: 0.5969 - recall: 0.1229 - val_loss: 0.6976 - val_accuracy: 0.5467 - val_recall: 0.0516\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.6611 - accuracy: 0.5997 - recall: 0.2373 - val_loss: 0.7010 - val_accuracy: 0.5493 - val_recall: 0.0649\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.6495 - accuracy: 0.6260 - recall: 0.3510 - val_loss: 0.6737 - val_accuracy: 0.5680 - val_recall: 0.3289\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.6361 - accuracy: 0.6469 - recall: 0.3665 - val_loss: 0.6807 - val_accuracy: 0.5887 - val_recall: 0.5531\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.6290 - accuracy: 0.6483 - recall: 0.4061 - val_loss: 0.6914 - val_accuracy: 0.5660 - val_recall: 0.7670\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.6212 - accuracy: 0.6574 - recall: 0.4336 - val_loss: 0.6804 - val_accuracy: 0.5907 - val_recall: 0.4469\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.6176 - accuracy: 0.6683 - recall: 0.4463 - val_loss: 0.6799 - val_accuracy: 0.6040 - val_recall: 0.3186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1018a60>"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Masking(mask_value=0., input_shape=(117,50)))\n",
    "model.add(layers.LSTM(80))\n",
    "model.add(layers.Dense(60, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy', 'Recall'])\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "model.fit(X_train_pad_2, y_train_2, epochs=100, batch_size=16, verbose=1, callbacks=[es], validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "3c95e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 117, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 117, 50), dtype=tf.float32, name='masking_9_input'), name='masking_9_input', description=\"created by layer 'masking_9_input'\"), but it was called on an input with incompatible shape (None, 116, 50).\n",
      "82/82 [==============================] - 2s 16ms/step - loss: 0.6546 - accuracy: 0.6219 - recall: 0.3951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.654558002948761, 0.6218905448913574, 0.39507222175598145]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_pad_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c895a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
